<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Juan S2V Open Model Released for Image-to-Video Animation</title>
    <style>
        body { font-family: Arial, sans-serif; line-height: 1.6; margin: 0; padding: 20px; max-width: 800px; margin: 0 auto; }
        h1 { color: #333; }
        .article-meta { color: #666; font-size: 0.9em; margin-bottom: 20px; }
        .article-content { margin-bottom: 30px; }
        .article-source { font-style: italic; }
        img { max-width: 100%; height: auto; }
    </style>
</head>
<body>
    <h1>Juan S2V Open Model Released for Image-to-Video Animation</h1>
    <div class="article-meta">
        <p>Published: Sun, 31 Aug 2025</p>
    </div>
    <div class="article-content">
        <p>A new open model called Juan S2V has been released that can animate still images based on audio input, adding realistic facial expressions and movements. While the model is publicly available on Hugging Face and Model Scope Studio, current server demand means generation times can be extremely long (4 hours on Hugging Face, 30 minutes on Model Scope). Users with powerful GPUs like the 4080 may have better results running it locally via GitHub.</p><p>Source: https://www.youtube.com/watch?v=TPiopAtoho4</p>
    </div>
    <div class="article-source">
        <p>Source: <a href="https://www.youtube.com/watch?v=usjPCQAoF44" target="_blank">https://www.youtube.com/watch?v=usjPCQAoF44</a></p>
    </div>
</body>
</html>