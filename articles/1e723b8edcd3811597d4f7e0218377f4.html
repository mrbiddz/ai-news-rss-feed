<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Meta Launches New Meta AI App</title>
    <style>
        body { font-family: Arial, sans-serif; line-height: 1.6; margin: 0; padding: 20px; max-width: 800px; margin: 0 auto; }
        h1 { color: #333; }
        .article-meta { color: #666; font-size: 0.9em; margin-bottom: 20px; }
        .article-content { margin-bottom: 30px; }
        .article-source { font-style: italic; }
        img { max-width: 100%; height: auto; }
    </style>
</head>
<body>
    <h1>Meta Launches New Meta AI App</h1>
    <div class="article-meta">
        <p>Published: Sat, 03 May 2025</p>
    </div>
    <div class="article-content">
        <p>Meta held their first ever Llamacon event, focusing specifically on AI advancements. The biggest announcement was the rebranding of the Meta View app to the Meta AI app, which now includes a standalone AI chat feature powered by Llama 4. The app allows users to have conversations with the AI, generate images using Meta's emu image generator, and share conversations to a social feed. Users can also continue conversations across devices, starting on Ray-Ban Meta glasses and continuing on the phone app or web. Meta has updated their privacy policy, noting that voice recordings will be stored in the cloud for up to a year to improve their products, though photos and videos won't be used for training. According to Mark Zuckerberg's Q1 2025 earnings call, Meta plans to eventually incorporate ads or product recommendations within Meta AI, though this won't happen for at least a year.</p><p>Source: https://www.youtube.com/watch?v=w20FT5quE_k</p>
    </div>
    <div class="article-source">
        <p>Source: <a href="https://www.youtube.com/watch?v=usjPCQAoF44" target="_blank">https://www.youtube.com/watch?v=usjPCQAoF44</a></p>
    </div>
</body>
</html>